## 大文件上传-断点续传


### 方法1
基于上面一个栗子进行改进，服务端已保存了部分片段，重新上传的时候，服务端对当前的分段进行对比，只接收本地没有的分段，前提是分段大小一致。

在上面为了方便，使用了时间戳作为这个文件的标志，其实可以使用spark-md5来生成文件的 hash 值，这样服务器就可以进行文件的对比了。

但是不好的地方是每个分段都要重新发送请求。

### 方法2 - 断点续传
方法1中，重新上传时请求和数据还会发到服务器，其实已上传的分段就不应该再发送到服务器了，所以我们可以使用断点续传来进行改进。

为每个分段生成 hash 值，使用  spark-md5  库
将上传成功的分段信息保存到本地
重新上传时，进行和本地分段 hash 值的对比，如果相同的话则跳过，继续下一个分段的上传
